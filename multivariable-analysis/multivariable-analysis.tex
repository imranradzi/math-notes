\documentclass[a4paper,14pt]{extarticle}
\usepackage{color}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{centernot}
\usepackage{tikz}
\usepackage{caption}
\usepackage{tikz-cd}

\theoremstyle{definition}
\newtheorem*{theorem}{Theorem}
\newtheorem*{definition}{Definition}
\newtheorem*{lemma}{Lemma}
\newtheorem*{proposition}{Proposition}
\newtheorem*{eg}{Example}
\newtheorem*{remark}{Remark}

\begin{document}


\title{\textbf{Multivariable Analysis - MATH0019}}
\author{\textbf{Based on lectures by Prof Yiannis Petridis}\\ Notes taken by Imran Radzi}
\date{}
\maketitle

\pagenumbering{roman}
Notes based on the Autumn 2021 Multivariable Analysis lectures by Prof Yiannis Petridis.

\begingroup
\let\cleardoublepage\clearpage
\tableofcontents
\endgroup
\newpage
\pagenumbering{arabic}

\section{Review of Euclidean space and some linear algebra}
\subsection{Euclidean space}
Recall the \emph{Euclidean $n$-space} $\mathbb{R}^n$ \[\mathbb{R}^n=\{(x^1,x^2,\ldots,x^n)\,:\,x^i\in\mathbb{R}\}\]
Note that use of superscripts instead of subscripts. We also have the \emph{Euclidean norm} given by \[|x|=\Bigl((x^1)^2+\ldots+(x^n)^2\Bigr)^{\frac{1}{2}}\]
and the \emph{inner product} \[x\cdot y=\sum_{i=1}^n x^i\cdot y^i\] where \[x=(x^1,\ldots,x^n)\] \[y=(y^1,\ldots,y^n)\]

\noindent Recall the \emph{standard basis} \[\{e_1,e_2,\ldots,e_n\}\] where $e_i\in\mathbb{R}^n$ where the only non-zero component is the $i^{\text{th}}$ component whose value is 1.
Hence we can represent $x\in\mathbb{R}^n$ as \[x=\sum_{i=1}^n x^i e_i\]

\begin{proposition} \hfill
	\begin{enumerate}
		\item $|x|\geq0,\,|x|=0\iff x=0$
		\item $|x\cdot y|\leq|x||y|$ \hfill (Cauchy-Schwarz inequality)
		\item $|x+y|\leq|x|+|y|$ \hfill (Triangle inequality)
		\item $|a\cdot x|=|a|\cdot|x|$ \hfill (for $a\in\mathbb{R})$
		\item $x\cdot y=y\cdot x$
	\end{enumerate}
\end{proposition}

We may also write $x\cdot y=\langle x,y \rangle$ as the inner product is a bilinear form. Recall the properties of a bilinear form which are
\begin{enumerate}
	\item $\langle x_1+x_2,y\rangle=\langle x_1,y\rangle+\langle x_2,y\rangle$
	\item $\langle ax,y\rangle = a\langle x,y\rangle$
\end{enumerate}

Also note that \[\langle x,x\rangle = |x|^2\]

\subsection{Some linear algebra}
Recall that a mapping $T:\mathbb{R}^n\rightarrow\mathbb{R}^m$ is said to be \emph{linear} if and only if, for $x,y\in\mathbb{R}^n, \,a\in\mathbb{R}$,
\[T(x+y)=T(x)+T(y)\]\[T(a\cdot  x)=a\cdot T(x)\] Note that in both equations, the operations taking place on the left hand side is done in $\mathbb{R}^n$ and $\mathbb{R}^m$
on the right hand side.

\noindent Recall that we can recover $M$, the matrix representation of a linear mapping $T$ by applying $T$ to each of the standard basis. So if
\[T(e_j)=a_{1j}e_1+a_{2j}e_2+\ldots+a_{mj}e_m\]
then
\begin{eqnarray*}
	M&=&(a_{ij}) \\
	&=&[T]
\end{eqnarray*}
where $M$ (or as we shall denote $[T]$) is the $m\times n$ matrix representing the linear transformation $T$.
\[\begin{pmatrix}y^1\\y^2\\\vdots\\y^m\end{pmatrix}=M\begin{pmatrix}x^1\\x^2\\\vdots\\x^n\end{pmatrix}\]

\noindent If we have two mappings $T:\mathbb{R}^n\rightarrow\mathbb{R}^m$ and $S:\mathbb{R}^m\rightarrow\mathbb{R}^p$ where $[S]_{p\times m}$ represents the
$p\times m$ matrix representing the linear transformation $S$, then $S\circ T$ is a linear mapping from $\mathbb{R}^n$ to $\mathbb{R}^p$.
\[S\circ T:\mathbb{R}^n\rightarrow\mathbb{R}^p\] and \[[S\circ T]=[S][T]\]

\section{Functions and continuity}
A function $f:\mathbb{R}^n\rightarrow\mathbb{R}^m$ is called a \emph{vector field} if $m>1$, and a \emph{scalar field} if $m=1$. \\

If $f:\mathbb{R}^n\rightarrow\mathbb{R}^m$ then we have \[f=(f^1,f^2,\ldots,f^m)\] where \[f^i:\mathbb{R}^n\rightarrow\mathbb{R}\] so we can write
\begin{eqnarray*}
	f(x)&=&f^1(x)e_1+\ldots+f^m(x)e_m \\
		&=&\Bigl(f^1(x),\ldots,f^m(x)\Bigr)
\end{eqnarray*}
and we call each of these $f^i$'s the components of $f$.

\noindent Now we define a function $\pi^i:\mathbb{R}^m\rightarrow\mathbb{R}$ given by $\pi^i(y)=y^i$, so that
\[\pi^i(y^1,y^2,\ldots,y^m)=y^i\] and we call this the \emph{projection in the $i^{\text{th}}$ direction} (or the \emph{projection function}). This function is a linear transformation.

\begin{center}
\begin{tikzcd}[row sep=huge, column sep=large]
\mathbb{R}^n \arrow{r}{f}  \arrow{rd}[swap]{f^i=\pi^i\circ f} 
  & \mathbb{R}^m \arrow{d}{\pi^i} \\
    & \mathbb{R}
\end{tikzcd}
\end{center}

Sometimes instead of $\mathbb{R}^n$ we may define $f$ on a subset of $A\subset\mathbb{R}^n$, usually where $A$ is open, i.e., sometimes we have
$f:A\rightarrow\mathbb{R}^m$.

\subsection{Limits and continuity}
\begin{definition}
	Let $a\in\mathbb{R}^n, \,b\in\mathbb{R}^m$. We write $\lim\limits_{x\to a} f(x)=b$ to mean
	\[\forall\epsilon>0, \,\exists\delta>0\text{ such that } 0<|x-a|<\delta\implies|f(x)-b|<\epsilon\]
\end{definition}

\noindent We say $f$ is continuous at $a$ if and only if \[\lim\limits_{x\to a}f(x)= f(a)\]

\noindent $f$ is said to be continuous on a set $A$ if $f$ is continuous at $a$, for all $a\in A$.

\begin{theorem}[Combination theorem]
	Suppose that \[\lim\limits_{x\to a} f(x)=b\text{ and }\lim\limits_{x\to a} g(x)=c\] then,
	\begin{enumerate}
		\item $\lim\limits_{x\to a} \Bigl(f(x)+g(x)\Bigr)=b+c$
		\item If $\lambda\in\mathbb{R}$, then $\lim\limits_{x\to a} \Bigl(\lambda\cdot f(x)\Bigr)=\lambda\cdot b$
		\item $\lim\limits_{x\to a} f(x)\cdot g(x)=b\cdot c$
		\item $\lim\limits_{x\to a} |f(x)|=|b|$
	\end{enumerate}
\end{theorem}

\begin{proof} \hfill
	\begin{enumerate}
		\item[3.] \begin{eqnarray*}
				f(x)\cdot g(x)-b\cdot c&=&f(x)\cdot g(x)-b\cdot g(x) + b\cdot g(x)-b\cdot c \\
					&=&(f(x)-b)\cdot g(x) + b\cdot(g(x)-c)
			\end{eqnarray*}
			\begin{eqnarray*}
				|f(x)\cdot g(x)-b\cdot c|&\leq&|(f(x)-b)\cdot g(x)|+|b\cdot(g(x)-c)| \\
				&\leq&|f(x)-b|\cdot|g(x)|+|b|\cdot|g(x)-c|
			\end{eqnarray*}
			and $|f(x)-b|, |g(x)-c|$ both tend to 0 as $x\to a$, while $|g(x)|$ is bounded close to $a$, so the right hand side tends to 0.
		\item[4.] By the reverse triangle inequality, \[||f(x)|-|b||\leq|f(x)-b|\]
	\end{enumerate}
\end{proof}

Now note that a linear transformation $T:\mathbb{R}^n\rightarrow\mathbb{R}^m$ is continuous everywhere.

\begin{lemma}
	Given $T$ linear $T:\mathbb{R}^n\rightarrow\mathbb{R}^m$, there exists $M>0$ such that \[\forall x\in\mathbb{R}^n, \,|T(x)|\leq M|x|\]
\end{lemma}

\begin{proof}
	Given that $x=(x^1,x^2,\ldots,x^n)$, we can rewrite \[x=\sum_{i=1}^n x^i e_i\] and so as $T$ is linear, \[T(x)=\sum_{i=1}^n x^i T(e_i)\]
	and then, 
	\begin{eqnarray*}
		|T(x)|&=&|\sum_{i=1}^n x^i T(e_i)| \\
			&\leq&\sum_{i=1}^n|x^i||T(e_i)|\leq(\sum_{i=1}^n|x^i|^2)^\frac{1}{2}(\sum_{i=1}^n|T(e_i)|^2)^\frac{1}{2} \\
			&=&|x|(\sum_{i=1}^n|T(e_i)|^2)^\frac{1}{2}
	\end{eqnarray*}
	and so set \[M=|x|(\sum_{i=1}^n|T(e_i)|^2)^\frac{1}{2}\]
\end{proof}

Using this lemma we can prove $T$ to be continuous at $y\in\mathbb{R}^n$ as follows,
\[|T(x)-T(y)|=|T(x-y)|\leq M|x-y|\] Given $\epsilon>0$, we can simply take $\delta=\frac{\epsilon}{M}>0$.

\begin{remark} \hfill
	\begin{enumerate}
		\item Let $f:\mathbb{R}^n\rightarrow\mathbb{R}^m$. Then, \[f\text{ is continuous}\iff f^i\text{ is continuous for }i=1,\ldots,m\]
			Sufficiency follows by noting that $f^i=\pi^i\circ f$ and the fact that $\pi^i$ is continuous. Necessity is a simple exercise to prove.
		\item Polynomials in $n$-variables are continuous, for example, the function \[1024(x^4)^5(x^2)^3(x^5)^{29}\] is continuous. The same holds for rational functions
			\[R(x^1,\ldots,x^n)=\frac{P(x^1,\ldots,x^n)}{Q(x^1,\ldots,x^n)}\] where $P,Q$ are polynomials, continuous, where denominator is not equal to 0.
	\end{enumerate}
\end{remark}

\section{Derivatives}
\begin{definition}
	We define \[D_if(a)=\lim\limits_{h\to0}\frac{f(a^1,a^2,\ldots,a^{i-1},a^i+h,a^{i+1},\ldots,a^n)-f(a)}{h}\]
\end{definition}

\begin{eg}
	Let $f:\mathbb{R}^2\rightarrow\mathbb{R}$, so $f(x,y)$ is a function of two variables $x,y$. Then, 
	\[D_1f(a,b)=\lim\limits_{h\to0}\frac{f(a+h,b)-f(a,b)}{h}=\frac{\partial f}{\partial x}(a,b)\]
	\[D_2f(a,b)=\frac{\partial f}{\partial y}(a,b)\]
	and similarly for $\mathbb{R}^3\rightarrow\mathbb{R}$.
\end{eg}

\begin{definition}
	Let $f:\mathbb{R}^n\rightarrow\mathbb{R}^m$ (or replace $\mathbb{R}^n$ with $A$ open in $\mathbb{R}^n$), and let $a\in\mathbb{R}$. We say $f$ is \emph{differentiable}
	at $a\in\mathbb{R}^n$ if we can find a linear transformation $\lambda:\mathbb{R}^n\rightarrow\mathbb{R}^m$ such that 
	\begin{equation}
	\lim\limits_{h\to0}\frac{|f(a+h)-f(a)-\lambda(h)|}{|h|}=0
	\end{equation} We call $\lambda:\mathbb{R}^n\rightarrow\mathbb{R}^m$ the \emph{derivative} of $f$ at $a$, and we denote
	it by $Df(a)$.
\end{definition}

\begin{theorem}
	$\lambda$ as defined above is unique.
\end{theorem}

\begin{proof}
	If $f$ is differentiable at $a$ and $\lambda,\mu:\mathbb{R}^n\rightarrow\mathbb{R}^m$ both linear transformations that satisfy $(1)$, then \[\mu=\lambda\]
\end{proof}

\begin{proof}
	We need to prove that $\forall x\in\mathbb{R}^n$, that $\mu(x)=\lambda(x)$. We can assume $x\neq0$ since as $\mu,\lambda$ are linear (so they map $0$ to $0$). 
	\begin{eqnarray*}
		\frac{|\lambda(h)-\mu(h)|}{|h|}&=&\frac{|\lambda(h)+f(a)-f(a+h)+f(a+h)-f(a)-\mu(h)|}{|h|} \\
			&=&\frac{|\lambda(h)+f(a)-f(a+h)|}{|h|}+\frac{|f(a+h)-f(a)-\mu(h)|}{|h|}
	\end{eqnarray*}
	Now if we take limits as $h\to0$, then \[\lim\limits_{h\to0}\frac{|\lambda(h)-\mu(h)|}{|h|}=0\] If we take $t$ small, and let $tx=h$, then since $h\to0\iff t\to0$ we have
	\begin{eqnarray*}
		\lim\limits_{t\to0}\frac{|\lambda(tx)-\mu(tx)|}{|tx|}&=&\lim\limits_{t\to0}\frac{|t\lambda(x)-t\mu(x)|}{|t||x|}\\
				&=&\lim\limits_{t\to0}\frac{|t||\lambda(x)-\mu(x)|}{|t||x|}\\
				&=&\lim\limits_{t\to0}\frac{|\lambda(x)-\mu(x)|}{|x|}\\
				&=&\frac{|\lambda(x)-\mu(x)|}{|x|}
	\end{eqnarray*}
	which is equal to 0 as \[\lim\limits_{t\to0}\frac{|\lambda(tx)-\mu(tx)|}{|tx|}=0\] hence \[|\lambda(x)-\mu(x)|=0\] i.e., \[\lambda(x)=\mu(x)\]
\end{proof}

Note that for $h\in\mathbb{R}^m$, that \[\lambda(h)=Df(a)(h)\] so $Df(a)$ is a linear transformation, $Df(a):\mathbb{R}^n\rightarrow\mathbb{R}^m$. \\

We call the matrix representation of $Df(a):\mathbb{R}^n\rightarrow\mathbb{R}^m$ the \emph{Jacobian} of $f$ at $a$ (here we use the standard basis) and we denote it by
$f'(a)$. So, \[Df(a)(h)=f'(a)\begin{pmatrix}h^1\\h^2\\\vdots\\h^n\end{pmatrix}\] Note that the product of this operation is column $m$-vector ($m\times1$ matrix), an element of
$\mathbb{R}^m$.

\begin{definition}
	Let $f:\mathbb{R}^n\rightarrow\mathbb{R}$ (or replace $\mathbb{R}^n$ with any $A$ open in $\mathbb{R}^n$), and let $u\in\mathbb{R}^n$, where $u\neq0$. We define the
	\emph{directional derivative} of $f$ at $a\in\mathbb{R}^n$ in the $u$-direction by
	\[D_uf(a)=\lim\limits_{h\to0}\frac{f(a+hu)-f(a)}{h}\] (if it exists), where $h\in\mathbb{R}$. If $u=e_i$, then $D_uf(a)=D_if(a)$.
\end{definition}

\begin{theorem}
	If $f:\mathbb{R}^n\rightarrow\mathbb{R}^m$ is differentiable at $a\in\mathbb{R}^n$ then it is continuous at $a$.
\end{theorem}

\begin{proof}
	We want to show that \[\lim\limits_{h\to0}f(a+h)=f(a)\] Hence we proceed
	\begin{eqnarray*}
		\lim\limits_{h\to0}|f(a+h)-f(a)|&=&\lim\limits_{h\to0}|f(a+h)-f(a)-\lambda(h)+\lambda(h)|\\
				&\leq&\lim\limits_{h\to0}|f(a+h)-f(a)-\lambda(h)|+\lim\limits_{h\to0}|\lambda(h)|\\
				&\leq&\lim\limits_{h\to0}\frac{|f(a+h)-f(a)-\lambda(h)|}{|h|}|h|+\lim\limits_{h\to0}|\lambda(h)|\\
				&=&0
	\end{eqnarray*}
	so \[\lim\limits_{h\to0}|f(a+h)-f(a)|=0\]
\end{proof}

\begin{remark}
	If \[\lim\limits_{h\to0}\frac{|f(a+h)-f(a)-\lambda(h)|}{|h|}\] then letting $h=x-a$, we can write \[\lim\limits_{x\to a}\frac{|f(x)-f(a)-\lambda(x-a)|}{|x-a|}=0\]
	If we let $\phi(x)=f(x)-f(a)-\lambda(x-a)$, then we have that $\phi:\mathbb{R}^n\rightarrow\mathbb{R}^m$ and we can rewrite
	\[f(x)=f(a)+\lambda(x-a)+\phi(x)\] or, recalling that $\lambda=Df(a)$, \[f(x)=f(a)+Df(a)(x-a)+\phi(x)\] By definition, we have
	\[\lim\limits_{x\to a}\frac{|\phi(x)|}{|x-a|}=0\]
\end{remark}

\end{document}













































